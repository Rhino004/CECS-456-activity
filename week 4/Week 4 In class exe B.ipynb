{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "334bdffe",
   "metadata": {},
   "source": [
    "# 1. Bias-Variance Tradeoff, Overfitting & Underfitting\n",
    "You are working on a predictive model to detect fraudulent transactions using a decision tree classifier. Initially, you trained a very deep tree that performs well on the training set but poorly on new data. To address this, you tried a shallow tree, but its performance was suboptimal across both training and test sets.\n",
    "\n",
    "Questions:\n",
    "- How would you describe the bias-variance tradeoff in this situation?\n",
    "  The bias-variance is the balance between underfitting and overfitting.\n",
    "- Which of the models is suffering from high variance, and which one has high bias?\n",
    "  High variance is in overfitting because the deep decision tree has low training error but high test error and high bias appers in underfitting because the shallow decision tree has high error on both training and test sets.\n",
    "- What strategies can you use to achieve a balance between bias and variance?\n",
    "  To achieve balance we would have to select meaningful features, remove noise, and creat new informative features to improve model generalization.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3801a635",
   "metadata": {},
   "source": [
    "# 2. Accuracy, Precision, Recall, and Error Rate\n",
    "A healthcare startup is building a machine learning model to predict whether a patient has a rare disease based on their medical records. The dataset is highly imbalanced, with only 2% of cases being positive. Your team trained a logistic regression model and reported 98% accuracy.\n",
    "\n",
    "Questions:\n",
    "- Why is accuracy not the best metric in this case?\n",
    "  accuracy is not the best metric because of the imbalanced datasets because it can be misleading.\n",
    "- How would you calculate and interpret precision and recall in this scenario?\n",
    "  we would calculate the precision with true positives divided by true positives plues false positives and we can understand that many of the predicted postives cases are actually. For recall we would true positives divided by true positives plues false negatives. This measures how many actual positives cases were correctly identified.\n",
    "- If the recall is 70% and precision is 30%, what does this indicate about the model’s performance?\n",
    "  This means that we have an unbalance dataset and the model prioritizes high recall but at the cost of many incorrect predictions. This could lead to unnecessary medical tests and anxiety for patients.\n",
    "- What steps would you take to improve the model’s predictive ability?\n",
    "  I would extract relevant medical indicators to improve model accuracy and remove noisy or redundant featrues that contribute to false positives. Another thing I would try to do is balance the dataset with sampling\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b7afad",
   "metadata": {},
   "source": [
    "# 3. Area Under the ROC Curve (AUC-ROC)\n",
    "You built two classifiers to detect spam emails: Model A (a random forest) and Model B (a k-NN model). After evaluation, Model A has an AUC-ROC score of 0.85, while Model B has a score of 0.65.\n",
    "\n",
    "Questions:\n",
    "- What does the AUC-ROC score indicate about the performance of each model?\n",
    "  The AUC-ROC is the accuray of the model becuase in this cause it's the model's ability to distinguish between spam and non-spam emails.\n",
    "- If you were to deploy one of the models in a real-world email filtering system, which would you choose and why?\n",
    "  I would deploy model A because it's AUC-ROC value is higher than model B and will be distinguished emails and spams.\n",
    "- Suppose Model B’s AUC-ROC improves to 0.75 after hyperparameter tuning. How would you further assess whether it is ready for deployment?\n",
    "    I would assess the model by compare precision, recall and f1-score along with that I would check false positive and false negatives rates.Final to see if it is ready for deployment I would conduct real-world testing to collect data on the performances of the mdoel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6d6157",
   "metadata": {},
   "source": [
    "# 4. k-NN Distance Metrics and Feature Scaling\n",
    "Scenario: You are working with a k-NN classifier on a dataset with mixed features, including age (years), income ($), and number of purchases. After training the model, you notice that income has a dominant effect on the distance calculations.\n",
    "\n",
    "Questions:\n",
    "- Why does income have a dominant effect on k-NN distance calculations?\n",
    "- in k-NN is the distance calculation determine the closeness of data points and income has dominant can effect because it has a much larger numerical range than the other features.\n",
    "- How does feature scaling (e.g., Min-Max Scaling, Standardization) help in k-NN?\n",
    "- Scaling ensures that all features contribute equally to distance calculations and preventing features with larger rnages form dominating.\n",
    "- Suppose you are using Euclidean distance. Would feature scaling be necessary? Why or why not?\n",
    "- Even with Eclidean distance we would still use scaling becuase features with large values will dominate the distance calculation, reducing the impact of smaller-scaled features like age.\n",
    "- If the dataset contains categorical variables, how can k-NN handle them?\n",
    "- k-nn requires a numerical representation of all features. This means that categorical variables must be encoded before applying distance based calculation. K-NN can handle them with One-Hot encoding or Binary Encoding.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427d7eeb",
   "metadata": {},
   "source": [
    "# 5. Choosing the Optimal k Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "108a5ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define range for k values\n",
    "k_values = list(range(1, 21))\n",
    "cv_scores = []\n",
    "#haing low k is about high varances and \n",
    "# Perform cross-validation\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "# Select the best k\n",
    "best_k = k_values[np.argmax(cv_scores)]\n",
    "print(f\"Best k: {best_k}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8a0fd4-99b9-4af3-9bb9-30982e60f1c9",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- What does `cross_val_score` do in this code?\n",
    "- To find a balances of overfeeding and underfeeding\n",
    "- Why do we perform 5-fold cross-validation to choose `k`?\n",
    "- What does the `np.argmax(cv_scores)` function return, and why is it useful?\n",
    "- What happens if `k` is set too high? How would it affect bias and variance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8bf220",
   "metadata": {},
   "source": [
    "# 6. Effect of Different Distance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6d02dc-19fc-460d-9709-c03414e639f3",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- What is the difference between Euclidean and Manhattan distances?\n",
    "- In which cases would Manhattan distance be preferable over Euclidean?\n",
    "- How would using Minkowski distance generalize both Euclidean and Manhattan distances?\n",
    "- How do different distance metrics affect k-NN classification in high-dimensional data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53d5a34-43c0-4c05-95d9-8ae56cf8a8e9",
   "metadata": {},
   "source": [
    "# 7. Handling Imbalanced Data in k-NN\n",
    "\n",
    "Scenario: You are applying k-NN to a medical dataset where 95% of patients are healthy (negative class) and only 5% have a rare disease (positive class). The model achieves high accuracy but fails to detect positive cases.\n",
    "\n",
    "Questions:\n",
    "- Why does k-NN struggle with imbalanced datasets?\n",
    "- What are some techniques to handle imbalanced classes in k-NN? (e.g., weighted voting, SMOTE)\n",
    "- How does setting the `weights='distance'` parameter in `KNeighborsClassifier` help in this scenario?\n",
    "- If you were to use precision-recall curves instead of accuracy, how would that impact model evaluation?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e795f405-9e09-4a56-94a5-0157d37a0d6a",
   "metadata": {},
   "source": [
    "# 8. k-NN vs. Tree-Based Classifiers\n",
    "\n",
    "Scenario: You need to classify images into categories, and you are choosing between k-NN and Decision Trees.\n",
    "\n",
    "Questions:\n",
    "- What are the main advantages of k-NN compared to tree-based classifiers like Decision Trees or Random Forests?\n",
    "- When would tree-based models be a better choice than k-NN?\n",
    "- k-NN requires storing all training data for predictions. How does this impact its computational efficiency compared to tree-based classifiers?\n",
    "- How would a high-dimensional feature space affect k-NN’s performance?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cda8bc-7ea9-4a55-9b58-54096482f487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
